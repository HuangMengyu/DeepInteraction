{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuangMengyu/DeepInteraction/blob/main/assignment_4_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Pj_41VDCFK"
      },
      "outputs": [],
      "source": [
        "# !pip install Transformers\n",
        "# !pip install Datasets\n",
        "# !pip install Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLzxRzK1Demc"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# file paths for train and eval dataset\n",
        "train_file = \"/content/drive/MyDrive/Colab Notebooks/pa4/train.csv\"\n",
        "eval_file = \"/content/drive/MyDrive/Colab Notebooks/pa4/eval.csv\"\n",
        "\n",
        "# create train and eval set\n",
        "train_data = load_dataset(\"csv\", data_files=train_file)\n",
        "eval_data = load_dataset(\"csv\", data_files=eval_file)\n",
        "print(train_data.shape, eval_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J143uSbIFoMB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Pretrained tokenizer from BERT\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_helper(batch):\n",
        "    return bert_tokenizer(batch['review'], padding=True, truncation=True)\n",
        "\n",
        "train_data = train_data.map(tokenize_helper, batched=True)\n",
        "eval_data = eval_data.map(tokenize_helper, batched=True)\n",
        "print(train_data.shape, eval_data.shape)\n",
        "print(train_data['train'][0])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObrriwrsIyfL"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Classification model\n",
        "BERT = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XalZGKtJXhq"
      },
      "outputs": [],
      "source": [
        "# Compute trainable parameters\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"num of trainable parameter:\", count_trainable_parameters(BERT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d64TDF50Kftj"
      },
      "outputs": [],
      "source": [
        "# evaluation helper\n",
        "\n",
        "import evaluate\n",
        "\n",
        "accuracy_scorer = evaluate.load('accuracy')\n",
        "\n",
        "def evaluation_helper(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    return accuracy_scorer.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q31pZuKKoVx"
      },
      "outputs": [],
      "source": [
        "# training parameters\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# get training args\n",
        "def getTrainingArgs(output_dir, num_train_epochs, eval_strategy = 'epoch'):\n",
        "    return TrainingArguments(output_dir=output_dir,\n",
        "            num_train_epochs = epochs,\n",
        "            eval_strategy = 'epoch',\n",
        "            report_to= 'none'\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LXAh9RLNB6h"
      },
      "outputs": [],
      "source": [
        "# Trainer\n",
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "def getTrainer(model, training_args, train_set, eval_set, compute_metrics):\n",
        "    return Trainer(model=model,\n",
        "          args=training_args,\n",
        "          train_dataset=train_set,\n",
        "          eval_dataset=eval_set,\n",
        "          compute_metrics=compute_metrics,\n",
        "      )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shXQV81XN_pZ"
      },
      "outputs": [],
      "source": [
        "# finetune the whole BERT\n",
        "\n",
        "BERT = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# hypers\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/assignment_4\" #The output directory where the model predictions and checkpoints will be written\n",
        "epochs = 10 # num of epoches\n",
        "train_args = getTrainingArgs(output_dir, epochs)\n",
        "trainer = getTrainer(BERT, train_args, train_data['train'], eval_data, evaluation_helper)\n",
        "\n",
        "# evaluating\n",
        "result_before = trainer.evaluate() #accu before finetuning\n",
        "print(\"accuracy before finetuning\", result_before['eval_train_accuracy'])\n",
        "\n",
        "# training\n",
        "trainer.train()\n",
        "\n",
        "# evaluating\n",
        "result_after = trainer.evaluate() #accu after finetuning\n",
        "print(\"accuracy after finetuning\", result_after['eval_train_accuracy'])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}